{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "italic-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [t.split() for t in open('terms.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "former-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['part', '-', 'of', '-', 'speech', 'tagging'],\n",
       " ['word', '-', 'to', '-', 'word'],\n",
       " ['part', '-', 'of', '-', 'speech'],\n",
       " ['state', '-', 'ofthe', '-', 'art'],\n",
       " ['tree', '-', 'to', '-', 'string'],\n",
       " ['-', 'fold', 'cross', '-', 'validation'],\n",
       " ['end', '-', 'to', '-', 'end'],\n",
       " ['state', '-', 'of', '-', 'theart'],\n",
       " ['sequence', '-', 'to', '-', 'sequence'],\n",
       " ['context', '-', 'free', 'grammar']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "introductory-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/micusp.parquet', storage_options={'anon':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cathedral-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>micusp/BIO.G0.15.1.html</td>\n",
       "      <td>New York City, 1908: different colors of skin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micusp/BIO.G1.04.1.html</td>\n",
       "      <td>\\tThe fish-tetrapod transition has been calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>micusp/BIO.G3.03.1.html</td>\n",
       "      <td>\\tIntracellular electric fields are of great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micusp/BIO.G0.11.1.html</td>\n",
       "      <td>Environmental stresses to plants have been st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micusp/BIO.G1.01.1.html</td>\n",
       "      <td>\\tThe recurrent cholera pandemics have been re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename                                               text\n",
       "0  micusp/BIO.G0.15.1.html   New York City, 1908: different colors of skin...\n",
       "1  micusp/BIO.G1.04.1.html   \\tThe fish-tetrapod transition has been calle...\n",
       "2  micusp/BIO.G3.03.1.html   \\tIntracellular electric fields are of great ...\n",
       "3  micusp/BIO.G0.11.1.html   Environmental stresses to plants have been st...\n",
       "4  micusp/BIO.G1.01.1.html  \\tThe recurrent cholera pandemics have been re..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-welcome",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Remove non-specific terms**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-replacement",
   "metadata": {},
   "source": [
    "### spaCy Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experimental-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-rotation",
   "metadata": {},
   "source": [
    "Loading a processing pipeline.  This is a small English model.  Will be using part of speech labels only, so we will be excluding modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smoking-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', exclude=['parser', 'ner', 'lemmatizer', 'attribute_ruler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "experienced-result",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7efbacab0ae0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7efbaca54220>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "utility-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "worth-desire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " New York City, 1908: different colors of skin swirl in the great melting pot to produce a cultural medley.  Now imagine such a metropolis spreading to cover every last crevice on Earth.  Over time, people will weave to produce an unprecedented uniformity; once discrete identities would be lost.  Our heritages will be remembered only by the history texts in the hands of our progeny.  A similar effect can be observed in environmental systems: we are in danger of losing our global biodiversity to a monotonous fate.   The threat of invasive species is now greater than the world has ever witnessed.  The number of introductions caused by international commerce is enormous (Mooney and Cleland, 2001).  Although only a small portion of emigrants survive, those survivors have aggregated to form a giant global problem of bioinvasions (Mack et al., 2000).  Extensive studies have been done on many exotics, such as the zebra mussel Dreissena polymorpha, and their biological and ecological threats prompt human interest and intervention (Facon et al., 2006).  Environmentalists advocate the awareness of invasive species and governments spend millions to purge them.  However, species removal is not as simple as it seems; we must be aware that the removal of an invasive causes ecosystem disturbance, just like its introduction, and hasty action can cause irreparable damage to our global asset of biodiversity.  Extensive and specific studies of the risks and rewards of invasive species removal should be done before any actions to control a bioinvasion. The greatest danger in dealing with invasive species involves risks in disturbing an ecosystem, especially one that's already threatened by an exotic.  There are many studies being done on the effects of these unwanted immigrants, but precise mechanisms for these ecological disturbances are still unclear (Mack et al., 2000).  Even less understood are the consequences of their removal.  A study on the effects of introduced trout on frogs showed that native populations can dramatically rebound upon extirpation of the invasive predator (Vredenburg 2004).  However, studies like this may not have strong implications on the majority of bioinvasions.  This study was carried out in isolated mountain pools.  With the exception of the introduced trout, these ecosystems have had minimal disturbance and human contact.  This is quite different from many other bioinvasions that happen in peoples' backyards. Insufficient understanding of invasive mechanisms can have catastrophic ramifications.  In French Polynesia, the predatory land snail Euglandina rosea was deemed a fix to the economical threats of the giant African land snail Achatina fulica.  Convinced by experiences with A. fulica in Hawaii, a hasty French Polynesian government set this invasive control project into action (O'Foighil 2006).  The resultant extinction of nearly all endemic Partulid species is a painful lesson today (Coote and Loeve, 2003).  Hawaii and French Polynesia are both pacific archipelagos, but their differing ecosystems led to the tragedy of the Partulids.  Thus historical precedence cannot always be generalized and applied to foreign problems.  Specific studies of any target invasive and ecosystem must be done before drastic actions are carried out. The removal process itself is extremely tedious and in some cases near impossible.  The removal of trout from five isolated lakes in Sixty Lake Basin of California took six years (Vredenburg 2004).  Similar cleansing of downstream lakes that could receive upstream fish would require even greater efforts.  In the case of E. rosea in French Polynesia, removal is thought to be impossible.  The carnivorous snail has infested every corner of numerous French Polynesian islands, eliminating any possibility of Partulid reintroduction (Coote and Loeve 2006).   The ability of bioinvaders to hybridize with native species to produce a spectrum of pseudo-exotics exacerbates difficulties faced.  This is most common among plants, which can also undergo extremely rapid evolution (Callaway and Maron, 2006): in England native species of the genus Senecio have readily hybridized with exotics to produce offspring that have taken over the country (Facon et al. 2006).  In such cases, total extirpation of non-natives would require the elimination of more than one species and looms as a truly daunting task.  As can be seen, removal projects are not always pragmatic or even possible.  Studies like the English Senecio project help elicit the mechanisms for bioinvasion and gauge the practicality of control projects so we do not waste effort on an impossible task.  Similar research should be done on all exotics before invasive removal projects. The economic costs of invasive species total over one hundred billion dollars a year in the United States alone, and millions more are spent to control or eliminate them (Mack et al., 2006).  However, the benefits of such projects aren't always clear even upon completion.  We assume the noble goal of restoring a native ecosystem, yet actual outcomes can be less-than-equitable compromises.  In the mid 20th century the United States government extirpated arctic foxes that had been introduced to the Aleutian archipelago fifty years earlier (Croll et al., 2005).  Now half a century later, once fox-infested islands still bear the scars of the bioinvasion despite the success of the fox removal project.  Seabirds are slow to recolonize the once dangerous islands, and the lack of guano leaves them under blankets of tundra.  Again, research to understand the mechanisms of bioinvasions could have helped predict this outcome and prevent implementation of such wasted efforts. We launch invasive removal projects to save the natives; however, are we actually helping them by removing an invasive?  Environments that have been exposed to an exotic for sufficiently long periods have reestablished equilibrium: species have developed adaptations to cope with their new neighbors.   Off the coast of New England, mussels exposed to predatory crabs develop thicker shells as protection (Freeman and Byers, 2006).  In Australia, snakes evolved smaller relative head sizes to cope with the introduced toxic cane toads (Phillips and Shine, 2004).  These morphological changes represent investments to increase fitness in altered habitats.  The energy cost of these features is balanced by an increased ability to survive.  By removing invaders, we are eliminating the benefits of their adaptations.  These disturbances would leave the native species with just the adverse costs of thickened shells and smaller heads.  In dealing with bioinvasions, we must consider not only the native species, but also the dynamic ecosystems.  Disturbances can draw out unforeseen effects; like the fox removal project in Alaska, a disturbance with the noblest of purposes can fall short of recovery. Invasive species are a threat to the world's biodiversity, but their removal can be just as hazardous.  Even with the right goal, without proper planning and sufficient studies to understand target ecosystems, projects in invasive removal can prove futile or even produce dire consequences.  Fortunately for Partulids in French Polynesia, at least one extant member of each endangered clade has been discovered and some hope of recovery still exists (O'Foighil 2006).  Yet many organisms have no immediate relatives: the dead clades walking are survivors of past mass-extinction events and their loss would be irreparable (Jablonski 2001).   When controlling the global problem of invasive species, prevention outshines restoration.  Most modern invasives are spread by artificially, either as unwitting stowaways or intentional imports.  However for the average citizen, the awareness of biodiversity is often masked by personal, political, and economic concern.  The threat of bioinvasions must be publicized and personalized.  Only thru the aggregation of countless personal efforts can a global threat be contained.  In New Zealand, invasive trout are a publicly supported economic boon (Townsend 2003).  Any extensive lobbying for the continued existence of a species is admirable.  If people were just as aware of the value in their endemic biodiversity, curbing the spread of exotic species would take an easier turn.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "burning-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " New York City, 1908: different colors of"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arctic-finnish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continuing-preview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NNP', '.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[200].tag_, doc[200].norm_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-filling",
   "metadata": {},
   "source": [
    "We will import the rule-based matcher from spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "studied-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quarterly-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Term', [[{'TAG': {'IN': ['JJ', 'NN']}},  #JJ = adjective  #NN = noun\n",
    "                      {'TAG': {'IN': ['JJ', 'NN', 'IN', 'HYPH']}, 'OP': '*'},  ##IN = preposition ##HYPH = hyphenated speech\n",
    "                      {'TAG': 'NN'}]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "short-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = matcher(doc, as_spans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-hacker",
   "metadata": {},
   "source": [
    "This is the first candidate in the first document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fluid-might",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('skin', 'swirl')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(tok.norm_ for tok in spans[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-reputation",
   "metadata": {},
   "source": [
    "### Extract candidate terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indirect-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(text):\n",
    "    doc = nlp(text)  #tokenize and tag\n",
    "    spans = matcher(doc, as_spans=True)  #find all the tags\n",
    "    return [tuple(tok.norm_ for tok in span) for span in spans] #return a list of all spans converted into tuples of normalized strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "refined-dealer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('skin', 'swirl'),\n",
       " ('great', 'melting'),\n",
       " ('melting', 'pot'),\n",
       " ('great', 'melting', 'pot'),\n",
       " ('cultural', 'medley'),\n",
       " ('last', 'crevice'),\n",
       " ('unprecedented', 'uniformity'),\n",
       " ('similar', 'effect'),\n",
       " ('global', 'biodiversity'),\n",
       " ('monotonous', 'fate'),\n",
       " ('invasive', 'species'),\n",
       " ('threat', 'of', 'invasive', 'species'),\n",
       " ('international', 'commerce'),\n",
       " ('small', 'portion'),\n",
       " ('global', 'problem'),\n",
       " ('giant', 'global', 'problem'),\n",
       " ('zebra', 'mussel'),\n",
       " ('human', 'interest'),\n",
       " ('ecosystem', 'disturbance'),\n",
       " ('hasty', 'action'),\n",
       " ('irreparable', 'damage'),\n",
       " ('global', 'asset'),\n",
       " ('asset', 'of', 'biodiversity'),\n",
       " ('global', 'asset', 'of', 'biodiversity'),\n",
       " ('invasive', 'predator'),\n",
       " ('minimal', 'disturbance'),\n",
       " ('human', 'contact'),\n",
       " ('insufficient', 'understanding'),\n",
       " ('predatory', 'land'),\n",
       " ('land', 'snail'),\n",
       " ('predatory', 'land', 'snail'),\n",
       " ('african', 'land'),\n",
       " ('giant', 'african', 'land'),\n",
       " ('land', 'snail'),\n",
       " ('african', 'land', 'snail'),\n",
       " ('giant', 'african', 'land', 'snail'),\n",
       " ('a.', 'fulica'),\n",
       " ('polynesian', 'government'),\n",
       " ('french', 'polynesian', 'government'),\n",
       " ('hasty', 'french', 'polynesian', 'government'),\n",
       " ('invasive', 'control'),\n",
       " ('control', 'project'),\n",
       " ('invasive', 'control', 'project'),\n",
       " ('project', 'into', 'action'),\n",
       " ('control', 'project', 'into', 'action'),\n",
       " ('invasive', 'control', 'project', 'into', 'action'),\n",
       " ('resultant', 'extinction'),\n",
       " ('painful', 'lesson'),\n",
       " ('lesson', 'today'),\n",
       " ('painful', 'lesson', 'today'),\n",
       " ('historical', 'precedence'),\n",
       " ('removal', 'process'),\n",
       " ('removal', 'of', 'trout'),\n",
       " ('similar', 'cleansing'),\n",
       " ('upstream', 'fish'),\n",
       " ('carnivorous', 'snail'),\n",
       " ('spectrum', 'of', 'pseudo'),\n",
       " ('rapid', 'evolution'),\n",
       " ('total', 'extirpation'),\n",
       " ('daunting', 'task'),\n",
       " ('practicality', 'of', 'control'),\n",
       " ('impossible', 'task'),\n",
       " ('similar', 'research'),\n",
       " ('invasive', 'removal'),\n",
       " ('noble', 'goal'),\n",
       " ('native', 'ecosystem'),\n",
       " ('20th', 'century'),\n",
       " ('mid', '20th', 'century'),\n",
       " ('aleutian', 'archipelago'),\n",
       " ('fox', 'removal'),\n",
       " ('removal', 'project'),\n",
       " ('fox', 'removal', 'project'),\n",
       " ('lack', 'of', 'guano'),\n",
       " ('invasive', 'removal'),\n",
       " ('relative', 'head'),\n",
       " ('toxic', 'cane'),\n",
       " ('energy', 'cost'),\n",
       " ('native', 'species'),\n",
       " ('native', 'species'),\n",
       " ('fox', 'removal'),\n",
       " ('removal', 'project'),\n",
       " ('fox', 'removal', 'project'),\n",
       " ('right', 'goal'),\n",
       " ('proper', 'planning'),\n",
       " ('invasive', 'removal'),\n",
       " ('extant', 'member'),\n",
       " ('hope', 'of', 'recovery'),\n",
       " ('mass', '-', 'extinction'),\n",
       " ('past', 'mass', '-', 'extinction'),\n",
       " ('global', 'problem'),\n",
       " ('average', 'citizen'),\n",
       " ('awareness', 'of', 'biodiversity'),\n",
       " ('economic', 'concern'),\n",
       " ('global', 'threat'),\n",
       " ('economic', 'boon'),\n",
       " ('extensive', 'lobbying'),\n",
       " ('continued', 'existence'),\n",
       " ('endemic', 'biodiversity')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidates(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-popularity",
   "metadata": {},
   "source": [
    "Now, we have to get all of the candidates for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wound-object",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf72e304d5cc43138b377ddeb7b620bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidates = list(concat(df['text'].progress_apply(get_candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-arizona",
   "metadata": {},
   "source": [
    "### Compute c-values\n",
    "\n",
    "$$\\mbox{C-value}(a)=\\begin{cases}\\log_2|a|\\cdot f(a) & \\mbox{if } a \\mbox{ is not nested}\\\\\\log_2|a|\\left(f(a)-\\frac{1}{P(T_a)}\\sum_{b\\in T_a}f(b)\\right) & \\mbox{otherwise}\\\\\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-juvenile",
   "metadata": {},
   "source": [
    "Next, we will count the frequencies of all the candidates and organize them by length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "joint-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "running-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = defaultdict(Counter)\n",
    "for c in candidates:\n",
    "    freqs[len(c)][c] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "female-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "provincial-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('trend', 'of', 'part', '-', 'time'), 15),\n",
       " (('asymmetry', 'in', 'stock', 'price', 'response'), 13),\n",
       " (('cycle', '-', 'to', '-', 'cycle'), 13),\n",
       " (('interaction', 'term', 'on', 'stock', 'price'), 10),\n",
       " (('basal', 'area', 'per', 'sample', 'area'), 9)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs[5].most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "balanced-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "killing-society",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use 5-1 = 4, to 1, but excluding 1 (use -1)\n",
    "list(range(4, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "egyptian-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subterms(term):\n",
    "    k = len(term)\n",
    "    for m in range(k-1, 1, -1):\n",
    "        yield from ngrams(term, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "above-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trend', 'of', 'part', '-'),\n",
       " ('of', 'part', '-', 'time'),\n",
       " ('trend', 'of', 'part'),\n",
       " ('of', 'part', '-'),\n",
       " ('part', '-', 'time'),\n",
       " ('trend', 'of'),\n",
       " ('of', 'part'),\n",
       " ('part', '-'),\n",
       " ('-', 'time')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_subterms(('trend', 'of', 'part', '-', 'time')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "coordinated-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "becoming-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_value(F, theta):\n",
    "    \n",
    "    termhood = Counter()\n",
    "    longer = defaultdict(list)\n",
    "    \n",
    "    for k in sorted(F, reverse=True):\n",
    "        for term in F[k]:\n",
    "            if term in longer:\n",
    "                discount = sum(longer[term]) / len(longer[term])\n",
    "            else:\n",
    "                discount = 0\n",
    "            c = log2(k) * (F[k][term] - discount)  #This is the extra boost given to longer sequences\n",
    "            if c > theta:\n",
    "                termhood[term] = c\n",
    "                for subterm in get_subterms(term):\n",
    "                    if subterm in F[len(subterm)]:\n",
    "                        longer[subterm].append(F[k][term])\n",
    "    return termhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "grateful-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = c_value(freqs, theta=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "generic-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  282.00  282 other hand\n",
      "  264.00  264 health care\n",
      "  252.00  126 part - time faculty\n",
      "  206.00  206 same time\n",
      "  177.52  112 long - term\n",
      "  169.00  169 high school\n",
      "  167.00  167 body color\n",
      "  155.33   98 self - esteem\n",
      "  146.00  146 wing venation\n",
      "  138.00  138 eye color\n",
      "  137.00  137 domestic violence\n",
      "  125.21   79 stock price response\n",
      "  120.46   76 decision - making\n",
      "  112.53   71 low - income\n",
      "  111.00  111 renewable energy\n",
      "  103.02   65 quality of life\n",
      "  103.02   65 state of nature\n",
      "  103.02   65 spell - caster\n",
      "  103.02   65 community violence exposure\n",
      "  101.00  101 wild type\n"
     ]
    }
   ],
   "source": [
    "for t, c in terms.most_common(20):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "thirty-intermediate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  137.00  137 domestic violence\n",
      "  125.21   79 stock price response\n",
      "  120.46   76 decision - making\n",
      "  112.53   71 low - income\n",
      "  111.00  111 renewable energy\n",
      "  103.02   65 quality of life\n",
      "  103.02   65 state of nature\n",
      "  103.02   65 spell - caster\n",
      "  103.02   65 community violence exposure\n",
      "  101.00  101 wild type\n",
      "   97.00   97 civil society\n",
      "   96.68   61 middle - class\n",
      "   96.00   48 psychological well - being\n",
      "   93.00   93 great deal\n",
      "   86.00   86 first time\n",
      "   84.00   84 social support\n",
      "   83.00   83 future research\n",
      "   83.00   83 sexual harassment\n",
      "   82.42   52 full - time\n",
      "   81.00   81 social movement\n"
     ]
    }
   ],
   "source": [
    "#Looking at the bottom of the list\n",
    "for t, c in tail(20, terms.most_common()):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:4d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "processed-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('terms-final.txt', 'w') as f:\n",
    "    for term in terms:\n",
    "        print(' '.join(term), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-yahoo",
   "metadata": {},
   "source": [
    "Combining both lists into one master list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "smart-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = open(\"terms.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "labeled-politics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part - of - speech tagging\n",
      "word - to - word\n",
      "part - of - speech\n",
      "state - ofthe - art\n",
      "tree - to - string\n",
      "- fold cross - validation\n",
      "end - to - end\n",
      "state - of - theart\n",
      "sequence - to - sequence\n",
      "context - free grammar\n",
      "right - hand side\n",
      "log - linear model\n",
      "- fold cross validation\n",
      "multi - document summarization\n",
      "inter - annotator agreement\n",
      "semi - supervised learning\n",
      "multi - task learning\n",
      "pre - trained word\n",
      "natural language processing\n",
      "high - level\n",
      "low - level\n",
      "machine translation system\n",
      "first - order\n",
      "sentence - level\n",
      "predicate - argument\n",
      "natural language generation\n",
      "point of view\n",
      "part of speech\n",
      "finite - state\n",
      "long - distance\n",
      "real - time\n",
      "word sense disambiguation\n",
      "co - occurrence\n",
      "trade - off\n",
      "large - scale\n",
      "real - world\n",
      "high - quality\n",
      "statistical machine translation\n",
      "n - gram\n",
      "long - term\n",
      "question - answer\n",
      "set of candidate\n",
      "number of training\n",
      "amount of training\n",
      "second - order\n",
      "word - level\n",
      "f - measure\n",
      "log - likelihood\n",
      "chinese word segmentation\n",
      "t - test\n",
      "character - level\n",
      "feed - forward\n",
      "document - level\n",
      "gram language model\n",
      "gold - standard\n",
      "open - domain\n",
      "f - score\n",
      "semantic role labeling\n",
      "self - training\n",
      "recurrent neural network\n",
      "stochastic gradient descent\n",
      "f1 - score\n",
      "low - resource\n",
      "hyper - parameter\n",
      "sub - word\n",
      "token - level\n",
      "target - side\n",
      "source - side\n",
      "ground - truth\n",
      "skip - gram\n",
      "neural machine translation\n",
      "encoder - decoder\n",
      "self - attention\n",
      "large number\n",
      "same way\n",
      "time complexity\n",
      "natural language\n",
      "previous work\n",
      "syntactic structure\n",
      "recent work\n",
      "logical form\n",
      "language understanding\n",
      "speech recognition\n",
      "related work\n",
      "standard deviation\n",
      "test set\n",
      "semantic information\n",
      "noun phrase\n",
      "next section\n",
      "small number\n",
      "parse tree\n",
      "sentence length\n",
      "other hand\n",
      "dependency structure\n",
      "phrase structure\n",
      "input sentence\n",
      "search space\n",
      "co -\n",
      "machine translation\n",
      "future research\n",
      "previous section\n",
      "word sense\n",
      "same sentence\n",
      "head word\n",
      "knowledge base\n",
      "semantic representation\n",
      "sub -\n",
      "sentence level\n",
      "contextual information\n",
      "large amount\n",
      "discourse structure\n",
      "average number\n",
      "current state\n",
      "future work\n",
      "single word\n",
      "same time\n",
      "cross -\n",
      "first step\n",
      "decision tree\n",
      "root node\n",
      "target language\n",
      "source language\n",
      "wide range\n",
      "english translation\n",
      "tree structure\n",
      "prior knowledge\n",
      "non -\n",
      "text generation\n",
      "feature set\n",
      "e -\n",
      "syntactic information\n",
      "lexical information\n",
      "beam search\n",
      "evaluation metric\n",
      "total number\n",
      "time step\n",
      "generative model\n",
      "dynamic programming\n",
      "phrase table\n",
      "information retrieval\n",
      "word pair\n",
      "training corpus\n",
      "training set\n",
      "mutual information\n",
      "similarity measure\n",
      "error rate\n",
      "dialog system\n",
      "morphological analysis\n",
      "linguistic knowledge\n",
      "re -\n",
      "semantic role\n",
      "word order\n",
      "semantic parsing\n",
      "neural network\n",
      "scoring function\n",
      "training time\n",
      "target word\n",
      "language model\n",
      "word level\n",
      "source word\n",
      "source sentence\n",
      "target sentence\n",
      "english word\n",
      "high precision\n",
      "hidden layer\n",
      "language pair\n",
      "maximum likelihood\n",
      "probabilistic model\n",
      "semantic similarity\n",
      "large corpus\n",
      "conditional probability\n",
      "small set\n",
      "language modeling\n",
      "translation model\n",
      "word sequence\n",
      "probability distribution\n",
      "overall performance\n",
      "input sequence\n",
      "local context\n",
      "% accuracy\n",
      "significant improvement\n",
      "test corpus\n",
      "data set\n",
      "vocabulary size\n",
      "feature space\n",
      "feature vector\n",
      "supervised learning\n",
      "baseline system\n",
      "classification task\n",
      "dependency tree\n",
      "word similarity\n",
      "dependency relation\n",
      "gram model\n",
      "error analysis\n",
      "automatic evaluation\n",
      "objective function\n",
      "correct answer\n",
      "classification problem\n",
      "distributional similarity\n",
      "maximum entropy\n",
      "high quality\n",
      "information extraction\n",
      "vector space\n",
      "vector representation\n",
      "learning rate\n",
      "context vector\n",
      "learning algorithm\n",
      "word segmentation\n",
      "window size\n",
      "ground truth\n",
      "context information\n",
      "translation quality\n",
      "baseline model\n",
      "development set\n",
      "edit distance\n",
      "_ b\n",
      "machine learning\n",
      "dialog act\n",
      "source domain\n",
      "parallel corpus\n",
      "word alignment\n",
      "sentence pair\n",
      "gold standard\n",
      "search engine\n",
      "prior work\n",
      "beam size\n",
      "batch size\n",
      "logistic regression\n",
      "weight vector\n",
      "binary classification\n",
      "coreference resolution\n",
      "dependency parser\n",
      "target side\n",
      "i t\n",
      "entity recognition\n",
      "active learning\n",
      "relation extraction\n",
      "feature selection\n",
      "validation set\n",
      "topic model\n",
      "dependency parsing\n",
      "target domain\n",
      "reinforcement learning\n",
      "cosine similarity\n",
      "joint model\n",
      "text classification\n",
      "human evaluation\n",
      "art performance\n",
      "domain adaptation\n",
      "loss function\n",
      "test time\n",
      "tree kernel\n",
      "hidden state\n",
      "sentiment classification\n",
      "sentiment analysis\n",
      "sequence labeling\n",
      "phrase pair\n",
      "h t\n",
      "distant supervision\n",
      "deep learning\n",
      "attention mechanism\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(terms.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "german-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_2 = open(\"terms-final.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "functioning-figure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part - time faculty\n",
      "psychological well - being\n",
      "long - term\n",
      "quality of life\n",
      "decision - making\n",
      "low - income\n",
      "middle - class\n",
      "stock price response\n",
      "self - esteem\n",
      "full - time\n",
      "state of nature\n",
      "spell - caster\n",
      "community violence exposure\n",
      "other hand\n",
      "same time\n",
      "first time\n",
      "wild type\n",
      "health care\n",
      "great deal\n",
      "high school\n",
      "renewable energy\n",
      "wing venation\n",
      "body color\n",
      "eye color\n",
      "future research\n",
      "domestic violence\n",
      "sexual harassment\n",
      "civil society\n",
      "social support\n",
      "social movement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(terms_2.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "billion-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms = [t for t in terms if t not in terms_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "changing-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_terms_final.txt\", \"w\") as output:\n",
    "    output.write(str(new_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-concentrate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
